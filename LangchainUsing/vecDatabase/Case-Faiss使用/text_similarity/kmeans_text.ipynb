{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaa9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\cheny\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89611, 7)\n",
      "      id      author                  source  \\\n",
      "0  89617         NaN  快科技@http://www.kkj.cn/   \n",
      "1  89616         NaN  快科技@http://www.kkj.cn/   \n",
      "2  89615         NaN  快科技@http://www.kkj.cn/   \n",
      "3  89614         NaN                     新华社   \n",
      "4  89613  胡淑丽_MN7479                   深圳大件事   \n",
      "\n",
      "                                             content  \\\n",
      "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
      "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...   \n",
      "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...   \n",
      "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n   \n",
      "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...   \n",
      "\n",
      "                                             feature  \\\n",
      "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...   \n",
      "1  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...   \n",
      "2  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...   \n",
      "3  {\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...   \n",
      "4  {\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...   \n",
      "\n",
      "                           title  \\\n",
      "0           小米MIUI 9首批机型曝光：共计15款   \n",
      "1     骁龙835在Windows 10上的性能表现有望改善   \n",
      "2      一加手机5细节曝光：3300mAh、充半小时用1天   \n",
      "3  葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）   \n",
      "4       44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随   \n",
      "\n",
      "                                                 url  \n",
      "0     http://www.cnbeta.com/articles/tech/623597.htm  \n",
      "1     http://www.cnbeta.com/articles/tech/623599.htm  \n",
      "2     http://www.cnbeta.com/articles/tech/623601.htm  \n",
      "3  http://world.huanqiu.com/hot/2017-06/10866126....  \n",
      "4  http://news.163.com/17/0618/00/CN617P3Q0001875...  \n",
      "         id author     source content  \\\n",
      "100   89517    NaN  中国证券报?中证网     NaN   \n",
      "103   89514    NaN  中国证券报?中证网     NaN   \n",
      "997   88620    NaN        央广网     NaN   \n",
      "1273  88344    NaN        央广网     NaN   \n",
      "1282  88335    NaN        央广网     NaN   \n",
      "\n",
      "                                                feature  \\\n",
      "100   {\"type\":\"公司\",\"site\":\"中证网\",\"commentNum\":\"0\",\"jo...   \n",
      "103   {\"type\":\"公司\",\"site\":\"中证网\",\"commentNum\":\"0\",\"jo...   \n",
      "997   {\"type\":\"时事要闻\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n",
      "1273  {\"type\":\"IT业界\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n",
      "1282  {\"type\":\"IT业界\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n",
      "\n",
      "                                 title  \\\n",
      "100       天和防务股东未来6个月内计划减持不超过480万股公司股份   \n",
      "103                    晶盛机电调整限制性股票回购价格   \n",
      "997              [主播不在家]第二季：主播陈亮体验垃圾清运   \n",
      "1273                LKK洛可可：想象力经济时代或已到来   \n",
      "1282  CES2017：京东发布两款叮咚智能音箱新品 开放Alpha平台   \n",
      "\n",
      "                                                    url  \n",
      "100   http://www.cs.com.cn/ssgs/gsxw/201706/t2017062...  \n",
      "103   http://www.cs.com.cn/ssgs/gsxw/201706/t2017062...  \n",
      "997   http://www.cankaoxiaoxi.com/china/20170623/214...  \n",
      "1273  http://www.cankaoxiaoxi.com/science/20170610/2...  \n",
      "1282  http://www.cankaoxiaoxi.com/science/20170610/2...  \n",
      "(87054, 7)\n",
      "此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/体验版内测，稳定版暂不受影响），以确保工程师可以集中全部精力进行系统优化工作。有人猜测这也是将精力主要用到MIUI 9的研发之中。\r\n",
      "MIUI 8去年5月发布，距今已有一年有余，也是时候更新换代了。\r\n",
      "当然，关于MIUI 9的确切信息，我们还是等待官方消息。\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.686 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 当然 MIUI9 确切 信息 等待 官方消息 更新换代  发布 含 开发 版 体验版 内测 稳定版 暂不受 影响 确保 工程师 集中 全部 精力 进行 系统优化 工作 有人 猜测 精力 主要 用到 MIUI9 研发 之中 \n",
      "(87054, 884)\n",
      "(87054, 884)\n",
      "accuracy: 0.889726997740935\n",
      "precison: 0.9623849539815926\n",
      "recall: 0.9141011022424933\n",
      "f1_score: 0.9376218323586745\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "# 加载停用词\n",
    "with open('chinese_stopwords.txt','r', encoding='utf-8') as file:\n",
    "    stopwords=[i[:-1] for i in file.readlines()]\n",
    "#stopwords = [line.strip() for line in open('chinsesstoptxt.txt',encoding='UTF-8').readlines()]\n",
    "\n",
    "# 数据加载\n",
    "news = pd.read_csv('sqlResult.csv',encoding='gb18030')\n",
    "print(news.shape)\n",
    "print(news.head(5))\n",
    "\n",
    "\n",
    "# 处理缺失值\n",
    "print(news[news.content.isna()].head(5))\n",
    "news=news.dropna(subset=['content'])\n",
    "print(news.shape)\n",
    "\n",
    "\n",
    "# 分词\n",
    "def split_text(text):\n",
    "    #return ' '.join([w for w in list(jieba.cut(re.sub('\\s|[%s]' % (punctuation),'',text))) if w not in stopwords])\n",
    "    text = text.replace(' ', '')\n",
    "    text = text.replace('\\n', '')\n",
    "    text2 = jieba.cut(text.strip())\n",
    "    result = ' '.join([w for w in text2 if w not in stopwords])\n",
    "    return result\n",
    "\n",
    "print(news.iloc[0].content)\n",
    "print(split_text(news.iloc[0].content))\n",
    "\n",
    "if not os.path.exists(\"corpus.pkl\"):\n",
    "    # 对所有文本进行分词\n",
    "    corpus=list(map(split_text,[str(i) for i in news.content]))\n",
    "    print(corpus[0])\n",
    "    print(len(corpus))\n",
    "    print(corpus[1])\n",
    "    # 保存到文件，方便下次调用\n",
    "    with open('corpus.pkl','wb') as file:\n",
    "        pickle.dump(corpus, file)\n",
    "else:\n",
    "    # 调用上次处理的结果\n",
    "    with open('corpus.pkl','rb') as file:\n",
    "        corpus = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "# 得到corpus的TF-IDF矩阵\n",
    "countvectorizer = CountVectorizer(encoding='gb18030',min_df=0.015)\n",
    "tfidftransformer = TfidfTransformer()\n",
    "\n",
    "countvector = countvectorizer.fit_transform(corpus)\n",
    "print(countvector.shape)\n",
    "\n",
    "tfidf = tfidftransformer.fit_transform(countvector)\n",
    "print(tfidf.shape)\n",
    "\n",
    "# 标记是否为自己的新闻\n",
    "label=list(map(lambda source: 1 if '新华' in str(source) else 0,news.source))\n",
    "#print(label)\n",
    "\n",
    "# 数据集切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf.toarray(), label, test_size = 0.3, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "\"\"\"\n",
    "# 进行CV=3折交叉验证\n",
    "scores=cross_validate(clf, X_train, y_train, scoring=('accuracy','precision','recall','f1'), cv=3, return_train_score=True)\n",
    "pprint(scores)\n",
    "\"\"\"\n",
    "y_predict = clf.predict(X_test)\n",
    "def show_test_reslt(y_true,y_pred):\n",
    "    print('accuracy:',accuracy_score(y_true,y_pred))\n",
    "    print('precison:',precision_score(y_true,y_pred))\n",
    "    print('recall:',recall_score(y_true,y_pred))\n",
    "    print('f1_score:',f1_score(y_true,y_pred))\n",
    "\n",
    "show_test_reslt(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d5bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可能为Copy的新闻条数： 2818\n",
      "0 11726\n",
      "1 8964\n",
      "2 3958\n",
      "3 6337\n",
      "4 4429\n",
      "5 1902\n",
      "6 722\n",
      "7 2431\n",
      "8 477\n",
      "9 1812\n",
      "10 1555\n",
      "11 1199\n",
      "12 3021\n",
      "13 6036\n",
      "14 4185\n",
      "15 3445\n",
      "16 3350\n",
      "17 3854\n",
      "18 877\n",
      "19 1975\n",
      "20 1590\n",
      "21 830\n",
      "22 1376\n",
      "23 1201\n",
      "24 1603\n"
     ]
    }
   ],
   "source": [
    "# 使用模型检测抄袭新闻\n",
    "prediction = clf.predict(tfidf.toarray())\n",
    "labels = np.array(label)\n",
    "# compare_news_index中有两列：prediction为预测，labels为真实值\n",
    "compare_news_index = pd.DataFrame({'prediction':prediction,'labels':labels})\n",
    "# copy_news_index：可能是Copy的新闻（即找到预测为1，但是实际不是“新华社”）\n",
    "copy_news_index=compare_news_index[(compare_news_index['prediction'] == 1) & (compare_news_index['labels'] == 0)].index\n",
    "# 实际为新华社的新闻\n",
    "xinhuashe_news_index=compare_news_index[(compare_news_index['labels'] == 1)].index\n",
    "print('可能为Copy的新闻条数：', len(copy_news_index))\n",
    "\n",
    "if not os.path.exists(\"label.pkl\"):\n",
    "    # 使用k-means对文章进行聚类\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    from sklearn.cluster import KMeans\n",
    "    normalizer = Normalizer()\n",
    "    scaled_array = normalizer.fit_transform(tfidf.toarray())\n",
    "\n",
    "    # 使用K-Means, 对全量文档进行聚类\n",
    "    kmeans = KMeans(n_clusters=25,random_state=42)\n",
    "    k_labels = kmeans.fit_predict(scaled_array)\n",
    "    # 保存到文件，方便下次调用\n",
    "    with open('label.pkl','wb') as file:\n",
    "        pickle.dump(k_labels, file)\n",
    "    print(k_labels.shape)\n",
    "    print(k_labels[0])\n",
    "else:\n",
    "    # 调用上次处理的结果\n",
    "    with open('label.pkl','rb') as file:\n",
    "        k_labels = pickle.load(file)\n",
    "\n",
    "if not os.path.exists(\"id_class.pkl\"):\n",
    "    # 创建id_class\n",
    "    id_class = {index:class_ for index, class_ in enumerate(k_labels)}\n",
    "    # 保存到文件，方便下次调用\n",
    "    with open('id_class.pkl','wb') as file:\n",
    "        pickle.dump(id_class, file)\n",
    "else:\n",
    "    # 调用上次处理的结果\n",
    "    with open('id_class.pkl','rb') as file:\n",
    "        id_class = pickle.load(file)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"class_id.pkl\"):\n",
    "    from collections import defaultdict\n",
    "    # 创建你class_id字段，key为classId,value为文档index\n",
    "    class_id = defaultdict(set)\n",
    "    for index,class_ in id_class.items():\n",
    "        # 只统计新华社发布的class_id\n",
    "        if index in xinhuashe_news_index.tolist():\n",
    "            class_id[class_].add(index)\n",
    "    # 保存到文件，方便下次调用\n",
    "    with open('class_id.pkl','wb') as file:\n",
    "        pickle.dump(class_id, file)\n",
    "else:\n",
    "    # 调用上次处理的结果\n",
    "    with open('class_id.pkl','rb') as file:\n",
    "        class_id = pickle.load(file)\n",
    "\n",
    "\n",
    "# 输出每个类别的 文档个数\n",
    "count=0\n",
    "for k in class_id:\n",
    "    print(count, len(class_id[k]))\n",
    "    count +=1\n",
    "\n",
    "# 查找相似文本（使用聚类结果进行filter）\n",
    "def find_similar_text(cpindex, top=10):\n",
    "    # 只在新华社发布的文章中查找\n",
    "    dist_dict={i:cosine_similarity(tfidf[cpindex],tfidf[i]) for i in class_id[id_class[cpindex]]}\n",
    "    # 从大到小进行排序\n",
    "    return sorted(dist_dict.items(),key=lambda x:x[1][0], reverse=True)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d27edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3134, array([[0.96849134]])), (63511, array([[0.94643198]])), (29441, array([[0.94283416]])), (3218, array([[0.87621892]])), (980, array([[0.87535155]])), (29615, array([[0.86936328]])), (29888, array([[0.86215862]])), (64046, array([[0.85278235]])), (29777, array([[0.84875422]])), (63974, array([[0.73415212]]))]\n",
      "怀疑抄袭:\n",
      " 　　中国5月份56座城市新建商品住宅价格环比上涨，4月份为58座上涨。5月份15个一线和热点二线城市房地产市场基本稳定，5月份房地产调控政策效果继续显现。\r\n",
      "　　统计局：15个一线和热点二线城市房价同比涨幅全部回落\r\n",
      "　　国家统计局城市司高级统计师刘建伟解读5月份房价数据\r\n",
      "　　5月份一二线城市房价平均涨幅继续回落\r\n",
      "　　国家统计局今日发布了2017年5月份70个大中城市住宅销售价格统计数据。对此，国家统计局城市司高级统计师刘建伟进行了解读。\r\n",
      "　　一、15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落、9个城市环比下降或持平\r\n",
      "　　5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\r\n",
      "　　二、70个大中城市中一二线城市房价同比涨幅持续回落\r\n",
      "　　5月份，70个城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\r\n",
      "　　三、70个大中城市中房价环比下降及涨幅回落城市个数均有所增加\r\n",
      "　　5月份，70个城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\r\n",
      "\n",
      "相似原文:\n",
      " 　　国家统计局19日发布数据，5月份，15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落，其中9个城市环比下降或持平。这9个价格环比下降或持平的城市为：北京、上海、南京、杭州、合肥、福州、郑州、深圳、成都。\r\n",
      "　　“5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。”国家统计局城市司高级统计师刘建伟说，从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\r\n",
      "　　国家统计局当天还发布了5月份70个大中城市住宅销售价格统计数据。刘建伟介绍，5月份，70个大中城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\r\n",
      "　　此外，70个大中城市中房价环比下降及涨幅回落城市个数均有所增加。统计显示，5月份，70个大中城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\r\n",
      "\n",
      "编辑距离: 315\n",
      "怀疑抄袭句:从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内\n",
      "相似原句:从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内\n",
      " 编辑距离:0\n",
      "\n",
      "怀疑抄袭句:其中，一二线城市同比涨幅回落尤其明显\n",
      "相似原句:其中，一二线城市同比涨幅回落尤其明显\n",
      " 编辑距离:0\n",
      "\n",
      "怀疑抄袭句:据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点\n",
      "相似原句:据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点\n",
      " 编辑距离:0\n",
      "\n",
      "怀疑抄袭句:二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个\n",
      "相似原句:二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个\n",
      " 编辑距离:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "# 指定某篇文章的相似度\n",
    "#print(copy_news_index)\n",
    "cpindex = 3352 # 在copy_news_index\n",
    "#print('是否在新华社', cpindex in xinhuashe_news_index)\n",
    "#print('是否在copy_news', cpindex in copy_news_index)\n",
    "#print('3134是否在新华社', 3134 in xinhuashe_news_index)\n",
    "#print('3134是否在copy_news', 3134 in copy_news_index)\n",
    "\n",
    "#print(cpindex)\n",
    "similar_list = find_similar_text(cpindex)\n",
    "print(similar_list)\n",
    "print('怀疑抄袭:\\n', news.iloc[cpindex].content)\n",
    "# 找一篇相似的原文\n",
    "similar2 = similar_list[0][0]\n",
    "print('相似原文:\\n', news.iloc[similar2].content)\n",
    "# 求任意两篇文章的编辑距离 \n",
    "print('编辑距离:',editdistance.eval(corpus[cpindex], corpus[similar2]))\n",
    "\n",
    "\n",
    "def find_similar_sentence(candidate, raw):\n",
    "    similist = []\n",
    "    cl = candidate.strip().split('。')\n",
    "    ra = raw.strip().split('。')\n",
    "    for c in cl:\n",
    "        for r in ra:\n",
    "            similist.append([c,r,editdistance.eval(c,r)])\n",
    "    # 最相似的5个句子\n",
    "    sort=sorted(similist,key=lambda x:x[2])[:5]\n",
    "    for c,r,ed in sort:\n",
    "        if c!='' and r!='':\n",
    "            print('怀疑抄袭句:{0}\\n相似原句:{1}\\n 编辑距离:{2}\\n'.format(c,r,ed))\n",
    "# 查找copy文章 和第一相似的原文的比对\n",
    "find_similar_sentence(news.iloc[cpindex].content, news.iloc[similar2].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
